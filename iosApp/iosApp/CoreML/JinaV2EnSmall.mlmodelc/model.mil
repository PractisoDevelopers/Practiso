program(1.0)
[buildInfo = dict<tensor<string, []>, tensor<string, []>>({{"coremlc-component-MIL", "3404.16.1"}, {"coremlc-version", "3404.23.1"}})]
{
    func main<ios16>(tensor<int32, [1, 512]> attention_mask, tensor<int32, [1, 512]> input_ids) {
            tensor<fp32, [30528, 512]> p_embeddings_word_embeddings_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [15630336]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(15630464))), name = tensor<string, []>("p_embeddings_word_embeddings_weight_palettized"), shape = tensor<uint32, [2]>([30528, 512])];
            tensor<fp32, [512]> p_embeddings_layernorm_weight = const()[name = tensor<string, []>("p_embeddings_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(15631552)))];
            tensor<fp32, [512]> p_embeddings_layernorm_bias = const()[name = tensor<string, []>("p_embeddings_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(15633664)))];
            tensor<fp32, [512, 512]> p_encoder_layer_0_attention_self_query_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(15635776))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(15897984))), name = tensor<string, []>("p_encoder_layer_0_attention_self_query_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_0_attention_self_query_bias = const()[name = tensor<string, []>("p_encoder_layer_0_attention_self_query_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(15899072)))];
            tensor<fp32, [512, 512]> p_encoder_layer_0_attention_self_key_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(15901184))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16163392))), name = tensor<string, []>("p_encoder_layer_0_attention_self_key_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_0_attention_self_key_bias = const()[name = tensor<string, []>("p_encoder_layer_0_attention_self_key_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16164480)))];
            tensor<fp32, [512, 512]> p_encoder_layer_0_attention_self_value_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16166592))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16428800))), name = tensor<string, []>("p_encoder_layer_0_attention_self_value_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_0_attention_self_value_bias = const()[name = tensor<string, []>("p_encoder_layer_0_attention_self_value_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16429888)))];
            tensor<fp32, [512, 512]> p_encoder_layer_0_attention_output_dense_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16432000))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16694208))), name = tensor<string, []>("p_encoder_layer_0_attention_output_dense_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_0_attention_output_dense_bias = const()[name = tensor<string, []>("p_encoder_layer_0_attention_output_dense_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16695296)))];
            tensor<fp32, [512]> p_encoder_layer_0_attention_output_layernorm_weight = const()[name = tensor<string, []>("p_encoder_layer_0_attention_output_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16697408)))];
            tensor<fp32, [512]> p_encoder_layer_0_attention_output_layernorm_bias = const()[name = tensor<string, []>("p_encoder_layer_0_attention_output_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16699520)))];
            tensor<fp32, [4096, 512]> p_encoder_layer_0_mlp_gated_layers_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [2097152]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16701632))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(18798848))), name = tensor<string, []>("p_encoder_layer_0_mlp_gated_layers_weight_palettized"), shape = tensor<uint32, [2]>([4096, 512])];
            tensor<fp32, [512, 2048]> p_encoder_layer_0_mlp_wo_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [1048576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(18799936))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19848576))), name = tensor<string, []>("p_encoder_layer_0_mlp_wo_weight_palettized"), shape = tensor<uint32, [2]>([512, 2048])];
            tensor<fp32, [512]> p_encoder_layer_0_mlp_wo_bias = const()[name = tensor<string, []>("p_encoder_layer_0_mlp_wo_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19849664)))];
            tensor<fp32, [512]> p_encoder_layer_0_mlp_layernorm_weight = const()[name = tensor<string, []>("p_encoder_layer_0_mlp_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19851776)))];
            tensor<fp32, [512]> p_encoder_layer_0_mlp_layernorm_bias = const()[name = tensor<string, []>("p_encoder_layer_0_mlp_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19853888)))];
            tensor<fp32, [512, 512]> p_encoder_layer_1_attention_self_query_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19856000))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20118208))), name = tensor<string, []>("p_encoder_layer_1_attention_self_query_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_1_attention_self_query_bias = const()[name = tensor<string, []>("p_encoder_layer_1_attention_self_query_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20119296)))];
            tensor<fp32, [512, 512]> p_encoder_layer_1_attention_self_key_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20121408))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20383616))), name = tensor<string, []>("p_encoder_layer_1_attention_self_key_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_1_attention_self_key_bias = const()[name = tensor<string, []>("p_encoder_layer_1_attention_self_key_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20384704)))];
            tensor<fp32, [512, 512]> p_encoder_layer_1_attention_self_value_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20386816))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20649024))), name = tensor<string, []>("p_encoder_layer_1_attention_self_value_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_1_attention_self_value_bias = const()[name = tensor<string, []>("p_encoder_layer_1_attention_self_value_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20650112)))];
            tensor<fp32, [512, 512]> p_encoder_layer_1_attention_output_dense_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20652224))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20914432))), name = tensor<string, []>("p_encoder_layer_1_attention_output_dense_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_1_attention_output_dense_bias = const()[name = tensor<string, []>("p_encoder_layer_1_attention_output_dense_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20915520)))];
            tensor<fp32, [512]> p_encoder_layer_1_attention_output_layernorm_weight = const()[name = tensor<string, []>("p_encoder_layer_1_attention_output_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20917632)))];
            tensor<fp32, [512]> p_encoder_layer_1_attention_output_layernorm_bias = const()[name = tensor<string, []>("p_encoder_layer_1_attention_output_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20919744)))];
            tensor<fp32, [4096, 512]> p_encoder_layer_1_mlp_gated_layers_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [2097152]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(20921856))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(23019072))), name = tensor<string, []>("p_encoder_layer_1_mlp_gated_layers_weight_palettized"), shape = tensor<uint32, [2]>([4096, 512])];
            tensor<fp32, [512, 2048]> p_encoder_layer_1_mlp_wo_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [1048576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(23020160))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24068800))), name = tensor<string, []>("p_encoder_layer_1_mlp_wo_weight_palettized"), shape = tensor<uint32, [2]>([512, 2048])];
            tensor<fp32, [512]> p_encoder_layer_1_mlp_wo_bias = const()[name = tensor<string, []>("p_encoder_layer_1_mlp_wo_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24069888)))];
            tensor<fp32, [512]> p_encoder_layer_1_mlp_layernorm_weight = const()[name = tensor<string, []>("p_encoder_layer_1_mlp_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24072000)))];
            tensor<fp32, [512]> p_encoder_layer_1_mlp_layernorm_bias = const()[name = tensor<string, []>("p_encoder_layer_1_mlp_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24074112)))];
            tensor<fp32, [512, 512]> p_encoder_layer_2_attention_self_query_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24076224))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24338432))), name = tensor<string, []>("p_encoder_layer_2_attention_self_query_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_2_attention_self_query_bias = const()[name = tensor<string, []>("p_encoder_layer_2_attention_self_query_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24339520)))];
            tensor<fp32, [512, 512]> p_encoder_layer_2_attention_self_key_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24341632))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24603840))), name = tensor<string, []>("p_encoder_layer_2_attention_self_key_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_2_attention_self_key_bias = const()[name = tensor<string, []>("p_encoder_layer_2_attention_self_key_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24604928)))];
            tensor<fp32, [512, 512]> p_encoder_layer_2_attention_self_value_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24607040))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24869248))), name = tensor<string, []>("p_encoder_layer_2_attention_self_value_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_2_attention_self_value_bias = const()[name = tensor<string, []>("p_encoder_layer_2_attention_self_value_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24870336)))];
            tensor<fp32, [512, 512]> p_encoder_layer_2_attention_output_dense_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(24872448))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(25134656))), name = tensor<string, []>("p_encoder_layer_2_attention_output_dense_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_2_attention_output_dense_bias = const()[name = tensor<string, []>("p_encoder_layer_2_attention_output_dense_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(25135744)))];
            tensor<fp32, [512]> p_encoder_layer_2_attention_output_layernorm_weight = const()[name = tensor<string, []>("p_encoder_layer_2_attention_output_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(25137856)))];
            tensor<fp32, [512]> p_encoder_layer_2_attention_output_layernorm_bias = const()[name = tensor<string, []>("p_encoder_layer_2_attention_output_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(25139968)))];
            tensor<fp32, [4096, 512]> p_encoder_layer_2_mlp_gated_layers_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [2097152]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(25142080))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(27239296))), name = tensor<string, []>("p_encoder_layer_2_mlp_gated_layers_weight_palettized"), shape = tensor<uint32, [2]>([4096, 512])];
            tensor<fp32, [512, 2048]> p_encoder_layer_2_mlp_wo_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [1048576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(27240384))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(28289024))), name = tensor<string, []>("p_encoder_layer_2_mlp_wo_weight_palettized"), shape = tensor<uint32, [2]>([512, 2048])];
            tensor<fp32, [512]> p_encoder_layer_2_mlp_wo_bias = const()[name = tensor<string, []>("p_encoder_layer_2_mlp_wo_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(28290112)))];
            tensor<fp32, [512]> p_encoder_layer_2_mlp_layernorm_weight = const()[name = tensor<string, []>("p_encoder_layer_2_mlp_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(28292224)))];
            tensor<fp32, [512]> p_encoder_layer_2_mlp_layernorm_bias = const()[name = tensor<string, []>("p_encoder_layer_2_mlp_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(28294336)))];
            tensor<fp32, [512, 512]> p_encoder_layer_3_attention_self_query_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(28296448))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(28558656))), name = tensor<string, []>("p_encoder_layer_3_attention_self_query_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_3_attention_self_query_bias = const()[name = tensor<string, []>("p_encoder_layer_3_attention_self_query_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(28559744)))];
            tensor<fp32, [512, 512]> p_encoder_layer_3_attention_self_key_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(28561856))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(28824064))), name = tensor<string, []>("p_encoder_layer_3_attention_self_key_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_3_attention_self_key_bias = const()[name = tensor<string, []>("p_encoder_layer_3_attention_self_key_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(28825152)))];
            tensor<fp32, [512, 512]> p_encoder_layer_3_attention_self_value_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(28827264))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29089472))), name = tensor<string, []>("p_encoder_layer_3_attention_self_value_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_3_attention_self_value_bias = const()[name = tensor<string, []>("p_encoder_layer_3_attention_self_value_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29090560)))];
            tensor<fp32, [512, 512]> p_encoder_layer_3_attention_output_dense_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29092672))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29354880))), name = tensor<string, []>("p_encoder_layer_3_attention_output_dense_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_encoder_layer_3_attention_output_dense_bias = const()[name = tensor<string, []>("p_encoder_layer_3_attention_output_dense_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29355968)))];
            tensor<fp32, [512]> p_encoder_layer_3_attention_output_layernorm_weight = const()[name = tensor<string, []>("p_encoder_layer_3_attention_output_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29358080)))];
            tensor<fp32, [512]> p_encoder_layer_3_attention_output_layernorm_bias = const()[name = tensor<string, []>("p_encoder_layer_3_attention_output_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29360192)))];
            tensor<fp32, [4096, 512]> p_encoder_layer_3_mlp_gated_layers_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [2097152]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29362304))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(31459520))), name = tensor<string, []>("p_encoder_layer_3_mlp_gated_layers_weight_palettized"), shape = tensor<uint32, [2]>([4096, 512])];
            tensor<fp32, [512, 2048]> p_encoder_layer_3_mlp_wo_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [1048576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(31460608))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32509248))), name = tensor<string, []>("p_encoder_layer_3_mlp_wo_weight_palettized"), shape = tensor<uint32, [2]>([512, 2048])];
            tensor<fp32, [512]> p_encoder_layer_3_mlp_wo_bias = const()[name = tensor<string, []>("p_encoder_layer_3_mlp_wo_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32510336)))];
            tensor<fp32, [512]> p_encoder_layer_3_mlp_layernorm_weight = const()[name = tensor<string, []>("p_encoder_layer_3_mlp_layernorm_weight"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32512448)))];
            tensor<fp32, [512]> p_encoder_layer_3_mlp_layernorm_bias = const()[name = tensor<string, []>("p_encoder_layer_3_mlp_layernorm_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32514560)))];
            tensor<fp32, [512, 512]> p_pooler_dense_weight_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32516672))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32778880))), name = tensor<string, []>("p_pooler_dense_weight_palettized"), shape = tensor<uint32, [2]>([512, 512])];
            tensor<fp32, [512]> p_pooler_dense_bias = const()[name = tensor<string, []>("p_pooler_dense_bias"), val = tensor<fp32, [512]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32779968)))];
            tensor<int32, [1]> unsqueeze_axes_0 = const()[name = tensor<string, []>("unsqueeze_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [1, 1, 512]> unsqueeze = expand_dims(axes = unsqueeze_axes_0, x = attention_mask)[name = tensor<string, []>("unsqueeze")];
            tensor<int32, [1]> unsqueeze_1_axes_0 = const()[name = tensor<string, []>("unsqueeze_1_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<int32, [1, 1, 1, 512]> unsqueeze_1 = expand_dims(axes = unsqueeze_1_axes_0, x = unsqueeze)[name = tensor<string, []>("unsqueeze_1")];
            tensor<string, []> cast_0_dtype_0 = const()[name = tensor<string, []>("cast_0_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<fp32, []> const_17 = const()[name = tensor<string, []>("const_17"), val = tensor<fp32, []>(0x1p+0)];
            tensor<fp32, [1, 1, 1, 512]> cast_0 = cast(dtype = cast_0_dtype_0, x = unsqueeze_1)[name = tensor<string, []>("cast_2")];
            tensor<fp32, [1, 1, 1, 512]> rsub = sub(x = const_17, y = cast_0)[name = tensor<string, []>("rsub")];
            tensor<fp32, []> const_18 = const()[name = tensor<string, []>("const_18"), val = tensor<fp32, []>(-0x1.fffffep+127)];
            tensor<fp32, [1, 1, 1, 512]> mul_23 = mul(x = rsub, y = const_18)[name = tensor<string, []>("mul_23")];
            tensor<int32, []> embedding_axis_0 = const()[name = tensor<string, []>("embedding_axis_0"), val = tensor<int32, []>(0)];
            tensor<int32, []> embedding_batch_dims_0 = const()[name = tensor<string, []>("embedding_batch_dims_0"), val = tensor<int32, []>(0)];
            tensor<fp32, [1, 512, 512]> embedding = gather(axis = embedding_axis_0, batch_dims = embedding_batch_dims_0, indices = input_ids, x = p_embeddings_word_embeddings_weight_palettized)[name = tensor<string, []>("embedding")];
            tensor<fp32, [1, 512, 512]> embedding_1_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [262144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32782080))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(33044288))), name = tensor<string, []>("embedding_1_palettized"), shape = tensor<uint32, [3]>([1, 512, 512])];
            tensor<fp32, [1, 512, 512]> add_24 = add(x = embedding, y = embedding_1_palettized)[name = tensor<string, []>("add_24")];
            tensor<fp32, []> const_21 = const()[name = tensor<string, []>("const_21"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<int32, [1]> layer_norm_axes_0 = const()[name = tensor<string, []>("layer_norm_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 512]> layer_norm = layer_norm(axes = layer_norm_axes_0, beta = p_embeddings_layernorm_bias, epsilon = const_21, gamma = p_embeddings_layernorm_weight, x = add_24)[name = tensor<string, []>("layer_norm")];
            tensor<fp32, [1, 8, 512, 512]> slice_8_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [2097152]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(33045376))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(35142592))), name = tensor<string, []>("slice_8_palettized"), shape = tensor<uint32, [4]>([1, 8, 512, 512])];
            tensor<fp32, [1, 512, 512]> linear = linear(bias = p_encoder_layer_0_attention_self_query_bias, weight = p_encoder_layer_0_attention_self_query_weight_palettized, x = layer_norm)[name = tensor<string, []>("linear_0")];
            tensor<fp32, [1, 512, 512]> linear_1 = linear(bias = p_encoder_layer_0_attention_self_key_bias, weight = p_encoder_layer_0_attention_self_key_weight_palettized, x = layer_norm)[name = tensor<string, []>("linear_1")];
            tensor<int32, [4]> concat_1 = const()[name = tensor<string, []>("concat_1"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view = reshape(shape = concat_1, x = linear_1)[name = tensor<string, []>("view")];
            tensor<fp32, [1, 512, 512]> linear_2 = linear(bias = p_encoder_layer_0_attention_self_value_bias, weight = p_encoder_layer_0_attention_self_value_weight_palettized, x = layer_norm)[name = tensor<string, []>("linear_2")];
            tensor<int32, [4]> concat_2 = const()[name = tensor<string, []>("concat_2"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view_1 = reshape(shape = concat_2, x = linear_2)[name = tensor<string, []>("view_1")];
            tensor<int32, [4]> const_41 = const()[name = tensor<string, []>("const_41"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> concat_3 = const()[name = tensor<string, []>("concat_3"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view_2 = reshape(shape = concat_3, x = linear)[name = tensor<string, []>("view_2")];
            tensor<bool, []> matmul_transpose_x_0 = const()[name = tensor<string, []>("matmul_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matmul_transpose_y_0 = const()[name = tensor<string, []>("matmul_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_16_perm_0 = const()[name = tensor<string, []>("transpose_16_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_17_perm_0 = const()[name = tensor<string, []>("transpose_17_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp32, [1, 8, 64, 512]> transpose_17 = transpose(perm = transpose_17_perm_0, x = view)[name = tensor<string, []>("transpose_38")];
            tensor<fp32, [1, 8, 512, 64]> transpose_16 = transpose(perm = transpose_16_perm_0, x = view_2)[name = tensor<string, []>("transpose_39")];
            tensor<fp32, [1, 8, 512, 512]> matmul = matmul(transpose_x = matmul_transpose_x_0, transpose_y = matmul_transpose_y_0, x = transpose_16, y = transpose_17)[name = tensor<string, []>("matmul")];
            tensor<fp32, []> _inversed_div_y_0 = const()[name = tensor<string, []>("_inversed_div_y_0"), val = tensor<fp32, []>(0x1p-3)];
            tensor<fp32, [1, 8, 512, 512]> _inversed_div = mul(x = matmul, y = _inversed_div_y_0)[name = tensor<string, []>("_inversed_div")];
            tensor<fp32, [1, 8, 512, 512]> add_80 = add(x = _inversed_div, y = mul_23)[name = tensor<string, []>("add_80")];
            tensor<fp32, [1, 8, 512, 512]> add_85 = add(x = add_80, y = slice_8_palettized)[name = tensor<string, []>("add_85")];
            tensor<int32, []> const_49 = const()[name = tensor<string, []>("const_49"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 8, 512, 512]> softmax = softmax(axis = const_49, x = add_85)[name = tensor<string, []>("softmax")];
            tensor<bool, []> matmul_1_transpose_x_0 = const()[name = tensor<string, []>("matmul_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matmul_1_transpose_y_0 = const()[name = tensor<string, []>("matmul_1_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 8, 512, 64]> permute_1 = transpose(perm = const_41, x = view_1)[name = tensor<string, []>("transpose_37")];
            tensor<fp32, [1, 8, 512, 64]> matmul_1 = matmul(transpose_x = matmul_1_transpose_x_0, transpose_y = matmul_1_transpose_y_0, x = softmax, y = permute_1)[name = tensor<string, []>("matmul_1")];
            tensor<int32, [4]> const_52 = const()[name = tensor<string, []>("const_52"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> concat_4 = const()[name = tensor<string, []>("concat_4"), val = tensor<int32, [3]>([1, 512, 512])];
            tensor<fp32, [1, 512, 8, 64]> permute_3 = transpose(perm = const_52, x = matmul_1)[name = tensor<string, []>("transpose_36")];
            tensor<fp32, [1, 512, 512]> view_3 = reshape(shape = concat_4, x = permute_3)[name = tensor<string, []>("view_3")];
            tensor<fp32, [1, 512, 512]> linear_3 = linear(bias = p_encoder_layer_0_attention_output_dense_bias, weight = p_encoder_layer_0_attention_output_dense_weight_palettized, x = view_3)[name = tensor<string, []>("linear_3")];
            tensor<fp32, [1, 512, 512]> add_119 = add(x = linear_3, y = layer_norm)[name = tensor<string, []>("add_119")];
            tensor<fp32, []> const_58 = const()[name = tensor<string, []>("const_58"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<int32, [1]> layer_norm_1_axes_0 = const()[name = tensor<string, []>("layer_norm_1_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 512]> layer_norm_1 = layer_norm(axes = layer_norm_1_axes_0, beta = p_encoder_layer_0_attention_output_layernorm_bias, epsilon = const_58, gamma = p_encoder_layer_0_attention_output_layernorm_weight, x = add_119)[name = tensor<string, []>("layer_norm_1")];
            tensor<fp32, [4096]> linear_4_bias_0_palettized = constexpr_lut_to_dense()[indices = tensor<uint8, [4096]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(35143680))), lut = tensor<fp32, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(35147840))), name = tensor<string, []>("linear_4_bias_0_palettized"), shape = tensor<uint32, [1]>([4096])];
            tensor<fp32, [1, 512, 4096]> linear_4 = linear(bias = linear_4_bias_0_palettized, weight = p_encoder_layer_0_mlp_gated_layers_weight_palettized, x = layer_norm_1)[name = tensor<string, []>("linear_4")];
            tensor<int32, [3]> slice_11_begin_0 = const()[name = tensor<string, []>("slice_11_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> slice_11_end_0 = const()[name = tensor<string, []>("slice_11_end_0"), val = tensor<int32, [3]>([1, 512, 2048])];
            tensor<bool, [3]> slice_11_end_mask_0 = const()[name = tensor<string, []>("slice_11_end_mask_0"), val = tensor<bool, [3]>([true, true, false])];
            tensor<fp32, [1, 512, 2048]> slice_11 = slice_by_index(begin = slice_11_begin_0, end = slice_11_end_0, end_mask = slice_11_end_mask_0, x = linear_4)[name = tensor<string, []>("slice_11")];
            tensor<int32, [3]> slice_14_begin_0 = const()[name = tensor<string, []>("slice_14_begin_0"), val = tensor<int32, [3]>([0, 0, 2048])];
            tensor<int32, [3]> slice_14_end_0 = const()[name = tensor<string, []>("slice_14_end_0"), val = tensor<int32, [3]>([1, 512, 1])];
            tensor<bool, [3]> slice_14_end_mask_0 = const()[name = tensor<string, []>("slice_14_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp32, [1, 512, 2048]> slice_14 = slice_by_index(begin = slice_14_begin_0, end = slice_14_end_0, end_mask = slice_14_end_mask_0, x = linear_4)[name = tensor<string, []>("slice_14")];
            tensor<string, []> gelu_mode_0 = const()[name = tensor<string, []>("gelu_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 2048]> gelu = gelu(mode = gelu_mode_0, x = slice_11)[name = tensor<string, []>("gelu")];
            tensor<fp32, [1, 512, 2048]> mul_153 = mul(x = gelu, y = slice_14)[name = tensor<string, []>("mul_153")];
            tensor<fp32, [1, 512, 512]> linear_5 = linear(bias = p_encoder_layer_0_mlp_wo_bias, weight = p_encoder_layer_0_mlp_wo_weight_palettized, x = mul_153)[name = tensor<string, []>("linear_5")];
            tensor<fp32, [1, 512, 512]> add_159 = add(x = linear_5, y = layer_norm_1)[name = tensor<string, []>("add_159")];
            tensor<fp32, []> const_80 = const()[name = tensor<string, []>("const_80"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<int32, [1]> layer_norm_2_axes_0 = const()[name = tensor<string, []>("layer_norm_2_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 512]> layer_norm_2 = layer_norm(axes = layer_norm_2_axes_0, beta = p_encoder_layer_0_mlp_layernorm_bias, epsilon = const_80, gamma = p_encoder_layer_0_mlp_layernorm_weight, x = add_159)[name = tensor<string, []>("layer_norm_2")];
            tensor<fp32, [1, 512, 512]> linear_6 = linear(bias = p_encoder_layer_1_attention_self_query_bias, weight = p_encoder_layer_1_attention_self_query_weight_palettized, x = layer_norm_2)[name = tensor<string, []>("linear_6")];
            tensor<fp32, [1, 512, 512]> linear_7 = linear(bias = p_encoder_layer_1_attention_self_key_bias, weight = p_encoder_layer_1_attention_self_key_weight_palettized, x = layer_norm_2)[name = tensor<string, []>("linear_7")];
            tensor<int32, [4]> concat_5 = const()[name = tensor<string, []>("concat_5"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view_4 = reshape(shape = concat_5, x = linear_7)[name = tensor<string, []>("view_4")];
            tensor<fp32, [1, 512, 512]> linear_8 = linear(bias = p_encoder_layer_1_attention_self_value_bias, weight = p_encoder_layer_1_attention_self_value_weight_palettized, x = layer_norm_2)[name = tensor<string, []>("linear_8")];
            tensor<int32, [4]> concat_6 = const()[name = tensor<string, []>("concat_6"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view_5 = reshape(shape = concat_6, x = linear_8)[name = tensor<string, []>("view_5")];
            tensor<int32, [4]> const_88 = const()[name = tensor<string, []>("const_88"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> concat_7 = const()[name = tensor<string, []>("concat_7"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view_6 = reshape(shape = concat_7, x = linear_6)[name = tensor<string, []>("view_6")];
            tensor<bool, []> matmul_2_transpose_x_0 = const()[name = tensor<string, []>("matmul_2_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matmul_2_transpose_y_0 = const()[name = tensor<string, []>("matmul_2_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_18_perm_0 = const()[name = tensor<string, []>("transpose_18_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_19_perm_0 = const()[name = tensor<string, []>("transpose_19_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp32, [1, 8, 64, 512]> transpose_19 = transpose(perm = transpose_19_perm_0, x = view_4)[name = tensor<string, []>("transpose_34")];
            tensor<fp32, [1, 8, 512, 64]> transpose_18 = transpose(perm = transpose_18_perm_0, x = view_6)[name = tensor<string, []>("transpose_35")];
            tensor<fp32, [1, 8, 512, 512]> matmul_2 = matmul(transpose_x = matmul_2_transpose_x_0, transpose_y = matmul_2_transpose_y_0, x = transpose_18, y = transpose_19)[name = tensor<string, []>("matmul_2")];
            tensor<fp32, []> _inversed_div_1_y_0 = const()[name = tensor<string, []>("_inversed_div_1_y_0"), val = tensor<fp32, []>(0x1p-3)];
            tensor<fp32, [1, 8, 512, 512]> _inversed_div_1 = mul(x = matmul_2, y = _inversed_div_1_y_0)[name = tensor<string, []>("_inversed_div_1")];
            tensor<fp32, [1, 8, 512, 512]> add_206 = add(x = _inversed_div_1, y = mul_23)[name = tensor<string, []>("add_206")];
            tensor<fp32, [1, 8, 512, 512]> add_211 = add(x = add_206, y = slice_8_palettized)[name = tensor<string, []>("add_211")];
            tensor<int32, []> const_96 = const()[name = tensor<string, []>("const_96"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 8, 512, 512]> softmax_1 = softmax(axis = const_96, x = add_211)[name = tensor<string, []>("softmax_1")];
            tensor<bool, []> matmul_3_transpose_x_0 = const()[name = tensor<string, []>("matmul_3_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matmul_3_transpose_y_0 = const()[name = tensor<string, []>("matmul_3_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 8, 512, 64]> permute_5 = transpose(perm = const_88, x = view_5)[name = tensor<string, []>("transpose_33")];
            tensor<fp32, [1, 8, 512, 64]> matmul_3 = matmul(transpose_x = matmul_3_transpose_x_0, transpose_y = matmul_3_transpose_y_0, x = softmax_1, y = permute_5)[name = tensor<string, []>("matmul_3")];
            tensor<int32, [4]> const_99 = const()[name = tensor<string, []>("const_99"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> concat_8 = const()[name = tensor<string, []>("concat_8"), val = tensor<int32, [3]>([1, 512, 512])];
            tensor<fp32, [1, 512, 8, 64]> permute_7 = transpose(perm = const_99, x = matmul_3)[name = tensor<string, []>("transpose_32")];
            tensor<fp32, [1, 512, 512]> view_7 = reshape(shape = concat_8, x = permute_7)[name = tensor<string, []>("view_7")];
            tensor<fp32, [1, 512, 512]> linear_9 = linear(bias = p_encoder_layer_1_attention_output_dense_bias, weight = p_encoder_layer_1_attention_output_dense_weight_palettized, x = view_7)[name = tensor<string, []>("linear_9")];
            tensor<fp32, [1, 512, 512]> add_245 = add(x = linear_9, y = layer_norm_2)[name = tensor<string, []>("add_245")];
            tensor<fp32, []> const_105 = const()[name = tensor<string, []>("const_105"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<int32, [1]> layer_norm_3_axes_0 = const()[name = tensor<string, []>("layer_norm_3_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 512]> layer_norm_3 = layer_norm(axes = layer_norm_3_axes_0, beta = p_encoder_layer_1_attention_output_layernorm_bias, epsilon = const_105, gamma = p_encoder_layer_1_attention_output_layernorm_weight, x = add_245)[name = tensor<string, []>("layer_norm_3")];
            tensor<fp32, [1, 512, 4096]> linear_10 = linear(bias = linear_4_bias_0_palettized, weight = p_encoder_layer_1_mlp_gated_layers_weight_palettized, x = layer_norm_3)[name = tensor<string, []>("linear_10")];
            tensor<int32, [3]> slice_17_begin_0 = const()[name = tensor<string, []>("slice_17_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> slice_17_end_0 = const()[name = tensor<string, []>("slice_17_end_0"), val = tensor<int32, [3]>([1, 512, 2048])];
            tensor<bool, [3]> slice_17_end_mask_0 = const()[name = tensor<string, []>("slice_17_end_mask_0"), val = tensor<bool, [3]>([true, true, false])];
            tensor<fp32, [1, 512, 2048]> slice_17 = slice_by_index(begin = slice_17_begin_0, end = slice_17_end_0, end_mask = slice_17_end_mask_0, x = linear_10)[name = tensor<string, []>("slice_17")];
            tensor<int32, [3]> slice_20_begin_0 = const()[name = tensor<string, []>("slice_20_begin_0"), val = tensor<int32, [3]>([0, 0, 2048])];
            tensor<int32, [3]> slice_20_end_0 = const()[name = tensor<string, []>("slice_20_end_0"), val = tensor<int32, [3]>([1, 512, 1])];
            tensor<bool, [3]> slice_20_end_mask_0 = const()[name = tensor<string, []>("slice_20_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp32, [1, 512, 2048]> slice_20 = slice_by_index(begin = slice_20_begin_0, end = slice_20_end_0, end_mask = slice_20_end_mask_0, x = linear_10)[name = tensor<string, []>("slice_20")];
            tensor<string, []> gelu_1_mode_0 = const()[name = tensor<string, []>("gelu_1_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 2048]> gelu_1 = gelu(mode = gelu_1_mode_0, x = slice_17)[name = tensor<string, []>("gelu_1")];
            tensor<fp32, [1, 512, 2048]> mul_275 = mul(x = gelu_1, y = slice_20)[name = tensor<string, []>("mul_275")];
            tensor<fp32, [1, 512, 512]> linear_11 = linear(bias = p_encoder_layer_1_mlp_wo_bias, weight = p_encoder_layer_1_mlp_wo_weight_palettized, x = mul_275)[name = tensor<string, []>("linear_11")];
            tensor<fp32, [1, 512, 512]> add_285 = add(x = linear_11, y = layer_norm_3)[name = tensor<string, []>("add_285")];
            tensor<fp32, []> const_127 = const()[name = tensor<string, []>("const_127"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<int32, [1]> layer_norm_4_axes_0 = const()[name = tensor<string, []>("layer_norm_4_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 512]> layer_norm_4 = layer_norm(axes = layer_norm_4_axes_0, beta = p_encoder_layer_1_mlp_layernorm_bias, epsilon = const_127, gamma = p_encoder_layer_1_mlp_layernorm_weight, x = add_285)[name = tensor<string, []>("layer_norm_4")];
            tensor<fp32, [1, 512, 512]> linear_12 = linear(bias = p_encoder_layer_2_attention_self_query_bias, weight = p_encoder_layer_2_attention_self_query_weight_palettized, x = layer_norm_4)[name = tensor<string, []>("linear_12")];
            tensor<fp32, [1, 512, 512]> linear_13 = linear(bias = p_encoder_layer_2_attention_self_key_bias, weight = p_encoder_layer_2_attention_self_key_weight_palettized, x = layer_norm_4)[name = tensor<string, []>("linear_13")];
            tensor<int32, [4]> concat_9 = const()[name = tensor<string, []>("concat_9"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view_8 = reshape(shape = concat_9, x = linear_13)[name = tensor<string, []>("view_8")];
            tensor<fp32, [1, 512, 512]> linear_14 = linear(bias = p_encoder_layer_2_attention_self_value_bias, weight = p_encoder_layer_2_attention_self_value_weight_palettized, x = layer_norm_4)[name = tensor<string, []>("linear_14")];
            tensor<int32, [4]> concat_10 = const()[name = tensor<string, []>("concat_10"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view_9 = reshape(shape = concat_10, x = linear_14)[name = tensor<string, []>("view_9")];
            tensor<int32, [4]> const_135 = const()[name = tensor<string, []>("const_135"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> concat_11 = const()[name = tensor<string, []>("concat_11"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view_10 = reshape(shape = concat_11, x = linear_12)[name = tensor<string, []>("view_10")];
            tensor<bool, []> matmul_4_transpose_x_0 = const()[name = tensor<string, []>("matmul_4_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matmul_4_transpose_y_0 = const()[name = tensor<string, []>("matmul_4_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_20_perm_0 = const()[name = tensor<string, []>("transpose_20_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_21_perm_0 = const()[name = tensor<string, []>("transpose_21_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp32, [1, 8, 64, 512]> transpose_21 = transpose(perm = transpose_21_perm_0, x = view_8)[name = tensor<string, []>("transpose_30")];
            tensor<fp32, [1, 8, 512, 64]> transpose_20 = transpose(perm = transpose_20_perm_0, x = view_10)[name = tensor<string, []>("transpose_31")];
            tensor<fp32, [1, 8, 512, 512]> matmul_4 = matmul(transpose_x = matmul_4_transpose_x_0, transpose_y = matmul_4_transpose_y_0, x = transpose_20, y = transpose_21)[name = tensor<string, []>("matmul_4")];
            tensor<fp32, []> _inversed_div_2_y_0 = const()[name = tensor<string, []>("_inversed_div_2_y_0"), val = tensor<fp32, []>(0x1p-3)];
            tensor<fp32, [1, 8, 512, 512]> _inversed_div_2 = mul(x = matmul_4, y = _inversed_div_2_y_0)[name = tensor<string, []>("_inversed_div_2")];
            tensor<fp32, [1, 8, 512, 512]> add_332 = add(x = _inversed_div_2, y = mul_23)[name = tensor<string, []>("add_332")];
            tensor<fp32, [1, 8, 512, 512]> add_337 = add(x = add_332, y = slice_8_palettized)[name = tensor<string, []>("add_337")];
            tensor<int32, []> const_143 = const()[name = tensor<string, []>("const_143"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 8, 512, 512]> softmax_2 = softmax(axis = const_143, x = add_337)[name = tensor<string, []>("softmax_2")];
            tensor<bool, []> matmul_5_transpose_x_0 = const()[name = tensor<string, []>("matmul_5_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matmul_5_transpose_y_0 = const()[name = tensor<string, []>("matmul_5_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 8, 512, 64]> permute_9 = transpose(perm = const_135, x = view_9)[name = tensor<string, []>("transpose_29")];
            tensor<fp32, [1, 8, 512, 64]> matmul_5 = matmul(transpose_x = matmul_5_transpose_x_0, transpose_y = matmul_5_transpose_y_0, x = softmax_2, y = permute_9)[name = tensor<string, []>("matmul_5")];
            tensor<int32, [4]> const_146 = const()[name = tensor<string, []>("const_146"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> concat_12 = const()[name = tensor<string, []>("concat_12"), val = tensor<int32, [3]>([1, 512, 512])];
            tensor<fp32, [1, 512, 8, 64]> permute_11 = transpose(perm = const_146, x = matmul_5)[name = tensor<string, []>("transpose_28")];
            tensor<fp32, [1, 512, 512]> view_11 = reshape(shape = concat_12, x = permute_11)[name = tensor<string, []>("view_11")];
            tensor<fp32, [1, 512, 512]> linear_15 = linear(bias = p_encoder_layer_2_attention_output_dense_bias, weight = p_encoder_layer_2_attention_output_dense_weight_palettized, x = view_11)[name = tensor<string, []>("linear_15")];
            tensor<fp32, [1, 512, 512]> add_371 = add(x = linear_15, y = layer_norm_4)[name = tensor<string, []>("add_371")];
            tensor<fp32, []> const_152 = const()[name = tensor<string, []>("const_152"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<int32, [1]> layer_norm_5_axes_0 = const()[name = tensor<string, []>("layer_norm_5_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 512]> layer_norm_5 = layer_norm(axes = layer_norm_5_axes_0, beta = p_encoder_layer_2_attention_output_layernorm_bias, epsilon = const_152, gamma = p_encoder_layer_2_attention_output_layernorm_weight, x = add_371)[name = tensor<string, []>("layer_norm_5")];
            tensor<fp32, [1, 512, 4096]> linear_16 = linear(bias = linear_4_bias_0_palettized, weight = p_encoder_layer_2_mlp_gated_layers_weight_palettized, x = layer_norm_5)[name = tensor<string, []>("linear_16")];
            tensor<int32, [3]> slice_23_begin_0 = const()[name = tensor<string, []>("slice_23_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> slice_23_end_0 = const()[name = tensor<string, []>("slice_23_end_0"), val = tensor<int32, [3]>([1, 512, 2048])];
            tensor<bool, [3]> slice_23_end_mask_0 = const()[name = tensor<string, []>("slice_23_end_mask_0"), val = tensor<bool, [3]>([true, true, false])];
            tensor<fp32, [1, 512, 2048]> slice_23 = slice_by_index(begin = slice_23_begin_0, end = slice_23_end_0, end_mask = slice_23_end_mask_0, x = linear_16)[name = tensor<string, []>("slice_23")];
            tensor<int32, [3]> slice_26_begin_0 = const()[name = tensor<string, []>("slice_26_begin_0"), val = tensor<int32, [3]>([0, 0, 2048])];
            tensor<int32, [3]> slice_26_end_0 = const()[name = tensor<string, []>("slice_26_end_0"), val = tensor<int32, [3]>([1, 512, 1])];
            tensor<bool, [3]> slice_26_end_mask_0 = const()[name = tensor<string, []>("slice_26_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp32, [1, 512, 2048]> slice_26 = slice_by_index(begin = slice_26_begin_0, end = slice_26_end_0, end_mask = slice_26_end_mask_0, x = linear_16)[name = tensor<string, []>("slice_26")];
            tensor<string, []> gelu_2_mode_0 = const()[name = tensor<string, []>("gelu_2_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 2048]> gelu_2 = gelu(mode = gelu_2_mode_0, x = slice_23)[name = tensor<string, []>("gelu_2")];
            tensor<fp32, [1, 512, 2048]> mul_397 = mul(x = gelu_2, y = slice_26)[name = tensor<string, []>("mul_397")];
            tensor<fp32, [1, 512, 512]> linear_17 = linear(bias = p_encoder_layer_2_mlp_wo_bias, weight = p_encoder_layer_2_mlp_wo_weight_palettized, x = mul_397)[name = tensor<string, []>("linear_17")];
            tensor<fp32, [1, 512, 512]> add_411 = add(x = linear_17, y = layer_norm_5)[name = tensor<string, []>("add_411")];
            tensor<fp32, []> const_174 = const()[name = tensor<string, []>("const_174"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<int32, [1]> layer_norm_6_axes_0 = const()[name = tensor<string, []>("layer_norm_6_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 512]> layer_norm_6 = layer_norm(axes = layer_norm_6_axes_0, beta = p_encoder_layer_2_mlp_layernorm_bias, epsilon = const_174, gamma = p_encoder_layer_2_mlp_layernorm_weight, x = add_411)[name = tensor<string, []>("layer_norm_6")];
            tensor<fp32, [1, 512, 512]> linear_18 = linear(bias = p_encoder_layer_3_attention_self_query_bias, weight = p_encoder_layer_3_attention_self_query_weight_palettized, x = layer_norm_6)[name = tensor<string, []>("linear_18")];
            tensor<fp32, [1, 512, 512]> linear_19 = linear(bias = p_encoder_layer_3_attention_self_key_bias, weight = p_encoder_layer_3_attention_self_key_weight_palettized, x = layer_norm_6)[name = tensor<string, []>("linear_19")];
            tensor<int32, [4]> concat_13 = const()[name = tensor<string, []>("concat_13"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view_12 = reshape(shape = concat_13, x = linear_19)[name = tensor<string, []>("view_12")];
            tensor<fp32, [1, 512, 512]> linear_20 = linear(bias = p_encoder_layer_3_attention_self_value_bias, weight = p_encoder_layer_3_attention_self_value_weight_palettized, x = layer_norm_6)[name = tensor<string, []>("linear_20")];
            tensor<int32, [4]> concat_14 = const()[name = tensor<string, []>("concat_14"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view_13 = reshape(shape = concat_14, x = linear_20)[name = tensor<string, []>("view_13")];
            tensor<int32, [4]> const_182 = const()[name = tensor<string, []>("const_182"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> concat_15 = const()[name = tensor<string, []>("concat_15"), val = tensor<int32, [4]>([1, 512, 8, 64])];
            tensor<fp32, [1, 512, 8, 64]> view_14 = reshape(shape = concat_15, x = linear_18)[name = tensor<string, []>("view_14")];
            tensor<bool, []> matmul_6_transpose_x_0 = const()[name = tensor<string, []>("matmul_6_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matmul_6_transpose_y_0 = const()[name = tensor<string, []>("matmul_6_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_22_perm_0 = const()[name = tensor<string, []>("transpose_22_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_23_perm_0 = const()[name = tensor<string, []>("transpose_23_perm_0"), val = tensor<int32, [4]>([0, 2, -1, -3])];
            tensor<fp32, [1, 8, 64, 512]> transpose_23 = transpose(perm = transpose_23_perm_0, x = view_12)[name = tensor<string, []>("transpose_26")];
            tensor<fp32, [1, 8, 512, 64]> transpose_22 = transpose(perm = transpose_22_perm_0, x = view_14)[name = tensor<string, []>("transpose_27")];
            tensor<fp32, [1, 8, 512, 512]> matmul_6 = matmul(transpose_x = matmul_6_transpose_x_0, transpose_y = matmul_6_transpose_y_0, x = transpose_22, y = transpose_23)[name = tensor<string, []>("matmul_6")];
            tensor<fp32, []> _inversed_div_3_y_0 = const()[name = tensor<string, []>("_inversed_div_3_y_0"), val = tensor<fp32, []>(0x1p-3)];
            tensor<fp32, [1, 8, 512, 512]> _inversed_div_3 = mul(x = matmul_6, y = _inversed_div_3_y_0)[name = tensor<string, []>("_inversed_div_3")];
            tensor<fp32, [1, 8, 512, 512]> add_458 = add(x = _inversed_div_3, y = mul_23)[name = tensor<string, []>("add_458")];
            tensor<fp32, [1, 8, 512, 512]> add_463 = add(x = add_458, y = slice_8_palettized)[name = tensor<string, []>("add_463")];
            tensor<int32, []> const_190 = const()[name = tensor<string, []>("const_190"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 8, 512, 512]> softmax_3 = softmax(axis = const_190, x = add_463)[name = tensor<string, []>("softmax_3")];
            tensor<bool, []> matmul_7_transpose_x_0 = const()[name = tensor<string, []>("matmul_7_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> matmul_7_transpose_y_0 = const()[name = tensor<string, []>("matmul_7_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 8, 512, 64]> permute_13 = transpose(perm = const_182, x = view_13)[name = tensor<string, []>("transpose_25")];
            tensor<fp32, [1, 8, 512, 64]> matmul_7 = matmul(transpose_x = matmul_7_transpose_x_0, transpose_y = matmul_7_transpose_y_0, x = softmax_3, y = permute_13)[name = tensor<string, []>("matmul_7")];
            tensor<int32, [4]> const_193 = const()[name = tensor<string, []>("const_193"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> concat_16 = const()[name = tensor<string, []>("concat_16"), val = tensor<int32, [3]>([1, 512, 512])];
            tensor<fp32, [1, 512, 8, 64]> permute_15 = transpose(perm = const_193, x = matmul_7)[name = tensor<string, []>("transpose_24")];
            tensor<fp32, [1, 512, 512]> view_15 = reshape(shape = concat_16, x = permute_15)[name = tensor<string, []>("view_15")];
            tensor<fp32, [1, 512, 512]> linear_21 = linear(bias = p_encoder_layer_3_attention_output_dense_bias, weight = p_encoder_layer_3_attention_output_dense_weight_palettized, x = view_15)[name = tensor<string, []>("linear_21")];
            tensor<fp32, [1, 512, 512]> add_497 = add(x = linear_21, y = layer_norm_6)[name = tensor<string, []>("add_497")];
            tensor<fp32, []> const_199 = const()[name = tensor<string, []>("const_199"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<int32, [1]> layer_norm_7_axes_0 = const()[name = tensor<string, []>("layer_norm_7_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 512]> layer_norm_7 = layer_norm(axes = layer_norm_7_axes_0, beta = p_encoder_layer_3_attention_output_layernorm_bias, epsilon = const_199, gamma = p_encoder_layer_3_attention_output_layernorm_weight, x = add_497)[name = tensor<string, []>("layer_norm_7")];
            tensor<fp32, [1, 512, 4096]> linear_22 = linear(bias = linear_4_bias_0_palettized, weight = p_encoder_layer_3_mlp_gated_layers_weight_palettized, x = layer_norm_7)[name = tensor<string, []>("linear_22")];
            tensor<int32, [3]> slice_29_begin_0 = const()[name = tensor<string, []>("slice_29_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> slice_29_end_0 = const()[name = tensor<string, []>("slice_29_end_0"), val = tensor<int32, [3]>([1, 512, 2048])];
            tensor<bool, [3]> slice_29_end_mask_0 = const()[name = tensor<string, []>("slice_29_end_mask_0"), val = tensor<bool, [3]>([true, true, false])];
            tensor<fp32, [1, 512, 2048]> slice_29 = slice_by_index(begin = slice_29_begin_0, end = slice_29_end_0, end_mask = slice_29_end_mask_0, x = linear_22)[name = tensor<string, []>("slice_29")];
            tensor<int32, [3]> slice_32_begin_0 = const()[name = tensor<string, []>("slice_32_begin_0"), val = tensor<int32, [3]>([0, 0, 2048])];
            tensor<int32, [3]> slice_32_end_0 = const()[name = tensor<string, []>("slice_32_end_0"), val = tensor<int32, [3]>([1, 512, 1])];
            tensor<bool, [3]> slice_32_end_mask_0 = const()[name = tensor<string, []>("slice_32_end_mask_0"), val = tensor<bool, [3]>([true, true, true])];
            tensor<fp32, [1, 512, 2048]> slice_32 = slice_by_index(begin = slice_32_begin_0, end = slice_32_end_0, end_mask = slice_32_end_mask_0, x = linear_22)[name = tensor<string, []>("slice_32")];
            tensor<string, []> gelu_3_mode_0 = const()[name = tensor<string, []>("gelu_3_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 2048]> gelu_3 = gelu(mode = gelu_3_mode_0, x = slice_29)[name = tensor<string, []>("gelu_3")];
            tensor<fp32, [1, 512, 2048]> mul_519 = mul(x = gelu_3, y = slice_32)[name = tensor<string, []>("mul_519")];
            tensor<fp32, [1, 512, 512]> linear_23 = linear(bias = p_encoder_layer_3_mlp_wo_bias, weight = p_encoder_layer_3_mlp_wo_weight_palettized, x = mul_519)[name = tensor<string, []>("linear_23")];
            tensor<fp32, [1, 512, 512]> add_537 = add(x = linear_23, y = layer_norm_7)[name = tensor<string, []>("add_537")];
            tensor<fp32, []> const_221 = const()[name = tensor<string, []>("const_221"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<int32, [1]> layer_norm_8_axes_0 = const()[name = tensor<string, []>("layer_norm_8_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 512]> last_hidden_state_type_fp32 = layer_norm(axes = layer_norm_8_axes_0, beta = p_encoder_layer_3_mlp_layernorm_bias, epsilon = const_221, gamma = p_encoder_layer_3_mlp_layernorm_weight, x = add_537)[name = tensor<string, []>("layer_norm_8")];
            tensor<int32, [3]> select_begin_0 = const()[name = tensor<string, []>("select_begin_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> select_end_0 = const()[name = tensor<string, []>("select_end_0"), val = tensor<int32, [3]>([1, 1, 512])];
            tensor<bool, [3]> select_end_mask_0 = const()[name = tensor<string, []>("select_end_mask_0"), val = tensor<bool, [3]>([true, false, true])];
            tensor<bool, [3]> select_squeeze_mask_0 = const()[name = tensor<string, []>("select_squeeze_mask_0"), val = tensor<bool, [3]>([false, true, false])];
            tensor<fp32, [1, 512]> select = slice_by_index(begin = select_begin_0, end = select_end_0, end_mask = select_end_mask_0, squeeze_mask = select_squeeze_mask_0, x = last_hidden_state_type_fp32)[name = tensor<string, []>("select")];
            tensor<fp32, [1, 512]> linear_24 = linear(bias = p_pooler_dense_bias, weight = p_pooler_dense_weight_palettized, x = select)[name = tensor<string, []>("linear_24")];
            tensor<fp32, [1, 512]> pooler_output_type_fp32 = tanh(x = linear_24)[name = tensor<string, []>("tanh")];
            tensor<string, []> cast_27_dtype_0 = const()[name = tensor<string, []>("cast_27_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<string, []> cast_28_dtype_0 = const()[name = tensor<string, []>("cast_28_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<fp16, [1, 512, 512]> last_hidden_state = cast(dtype = cast_27_dtype_0, x = last_hidden_state_type_fp32)[name = tensor<string, []>("cast_0")];
            tensor<fp16, [1, 512]> pooler_output = cast(dtype = cast_28_dtype_0, x = pooler_output_type_fp32)[name = tensor<string, []>("cast_1")];
        } -> (last_hidden_state, pooler_output);
}